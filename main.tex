\documentclass[runningheads,deutsch]{llncs}
%
\usepackage[T1]{fontenc}
%
\usepackage{graphicx}
%

% Daniel Motz's packages
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{stmaryrd}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{ bbold }
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

\setcounter{tocdepth}{3}

\usepackage{tikz}
\usepackage{tikz-3dplot}
\usepackage{pgfplots}
\pgfplotsset{compat = newest}

\usepackage{hyperref}

\usepackage{setspace}
\doublespacing

\usepackage{array}   % for \newcolumntype macro
\newcolumntype{C}{>{$}c<{$}} % math-mode version of "l" column type
\newcolumntype{L}{>{$}l<{$}} % math-mode version of "l" column type

\renewcommand{\abstractname}{}
\newcommand{\inline}{\mintinline[fontsize=\normalsize]{c++}{text}}
\newcommand{\estimates}{\overset{\scriptscriptstyle\wedge}{=}}
\DeclareUnicodeCharacter{03BB}{$\lambda$}

\newenvironment{indentleft}[1]{
    \setlength{\leftskip}{#1}
}{
    \setlength{\leftskip}{0pt}
}
\usepackage{cancel}
% END Daniel Motz's packages

\begin{document}
%
\title{
    Einführung in die Künstliche Intelligenz
}
%
\titlerunning{Einführung in die KI}%
\author{Maximilian Stock, Daniel Motz}
%
\authorrunning{M. Stock, D. Motz}
%
\institute{Fakultät für Mathematik und Informatik, Friedrich-Schiller-University,\\ Jena, Germany\\
\vspace{.2cm}
\email{maximilian.stock@uni-jena.de, daniel.motz@uni-jena.de}
}
%
\maketitle % typeset the header of the contribution
%

% Set paragraph indent to 0mm
\parindent0mm
\section{Der Gegenstandsbereich}
\subsection{Lernfragen}
\begin{description}
  \item[Was meint "KI"?] KI ist das Unterfangen, künstliche intelligente Systeme zu bauen. 
  \item[Der Turing-Test]
  \item["Starke" und "schwache" KI]
  \item[Symbolische KI vs. Konnektionismus]
\end{description}

\subsection{TODOs}
\begin{itemize}
    \item (Seite 10 FS 1) teleologischer Aspekt WB-Systeme verstehen
    \item (Seite 10 FS 1) "nach generellen Prinzipien strukturiert" verstehen
    \item (Seite 10 FS 1) Wissenstransfer, Erklärung. Was bedeutet das?
    \item (Seite 11 FS 1) Wissenstypen: Begriffe abgrenzen
    \item Hybride (letzte Seite) ergänzen
\end{itemize} 

\subsection*{Done TODOs}
\begin{itemize}
    \item Den "nicht-einfachen" Turing-Test (die Verhörsituation) verstehen
    \item Was ist eine einbettende Umgebung in einem PSS?
    \item PSS genauer definieren
    \item Starke und Schwache KI nach Searle verstehen
\end{itemize}

\subsection{Was ist KI?}

\subsubsection{1. Definitionsversuch}

KI ist das Unterfangen, künstliche intelligente Systeme zu \textit{bauen}.
Mit Intelligenz sind Aufgaben, die Menschen gut bewältigen gemeint. Sie
demonstrieren Intelligenz:

\begin{itemize}
    \item Bilderkennung
    \item Stimmerkennung
    \item Aufstellen vernünftigter Erwartungen (z.B. wenn etwas "John" heißt, erwarten wir, dass es sich nicht um ein Kino oder ein Eis, sondern wahrscheinlich um eine Person; vielleicht noch ein Haustier oder Ähnliches). 
\end{itemize}

Nicht alles, was der Mensch gut tut, ist interessant für die KI. 

Viele Aufgaben, die gemeinhin als schwierig (Intelligenz voraussetzen) gelten, sind zu \textit{speziell}: Das einzig intelligente, was ein Schachprogramm kann,m ist Schachspielen!

\subsubsection{Einfacher Turingtest}
\begin{itemize}
    \item Zwei Räume verbunden durch Fernschreiber
    \begin{itemize}
        \item in einem Raum der \textit{Tester}
        \item im anderen: \textit{Mensch} oder \textit{Maschine}
    \end{itemize}
    \item Tester hat 30 Minuten Zeit über den Fernschreiber herauszufinden, ob es sich um einen Menschen oder eine Maschine handelt.
\end{itemize}

\subsubsection{2. Definitionsversuch}

KI ist das Unterfangen, ein künstliches System zu bauen, das den Turingtest zuverlässig besteht.

\subsubsection{Der Turing-Test}
In einer "Verhörsituation" gibt es drei Personen, die sich gegenseitig nicht sehen und nur schriftlich kommunizieren können. Person A ist männlich, Person B ist weiblich und Person C hat ein beliebiges Geschlecht. Person C leitet das Verhör und soll bestimmen, welche der Personen welches Geschlecht hat. C kann beide mit X und Y ansprechen und muss am Ende A X und B Y oder B X und A Y zuordnen. A hat das Ziel, dass C die Geschlechter falsch bestimmt. Auch hier: Zeitlimit von 30 Minuten.

Nun fragen wir uns: "Was passiert, wenn eine Maschine die Rolle von A übernimmt?" 

\subsubsection{Einwände gegen den Turing-Test:}

Kann die Maschine als Mensch durchgehen, nur weil der Tester schlecht ist? (... z.B. einschläft ...) Man wiederholt den Test mehrfach. Der Test ist sinnfrei, wenn $B$ lügen kann, z.B. vorgibt ein Mann zu sein, weil die "Intelligenz" der Maschine dann irrelevant für den Test ist. Er ist auch sinnfrei, wenn $A$ nicht lügen darf. Man geht explizit davon aus, dass $B$ keine Agenda hat.

\subsubsection{Searle's Einwand}

Der Tester tippt nicht mehr als 10 Zeichen pro Sekunde. Die Maschine muss maximal 18.000 Zeichen beantworten. Da die Anzahl an möglichen Anfragen begrenzt ist, kann man in einer riesigen Tabelle alle möglichen Konfrontationen für diesen Dialog speichern und die Maschine kann mit ihrer Hilfe alle intelligenten Reaktionen nachschlagen. Hier scheiden sich die Geister. Wann ist eine KI eine KI und was muss sie können?


\begin{definition}{Die "starke" KI-Hypothese}

\dots eine \textit{funktionale Definition von Intelligenz} $\Rightarrow$ Turing-Test bestehen.

\end{definition}

\begin{definition}{Die "starke" und die "schwache" KI-Hypothese}

Eine schwache KI ist ein Werkzeug, das genau eine Klasse von Problemen lösen kann; zum Beispiel ein Schachcomputer. Für andere Probleme, etwa das steuern eines Fahrzeugs, ist er ungeeignet. Während eine schwache KI ihren Job nur anhand ihres Trainings erledigt, versteht eine starke KI ihre Aufgabe, und ist in der Lage eigenständig eine Lösungsstrategie zu entwickeln. Diese Fähigkeit zu argumentieren und zu abstrahieren, verleiht ihr außerdem die Fähigkeit, sich weiterzuentwickeln, sich zu verbessern und sich neue Fähigkeiten anzueignen. Sie ist autonom.

\end{definition}

\subsubsection{Was heißt hier "künstlich"?}

Minimalforderung: künstlich $\Rightarrow$ anorganisch. Bringt uns aber nicht weiter...

Besser: Ein künstliches System ist ein \textit{physical-symbol-system} (PSS) im Sinne von Newell und Simon. Ein PSS ist eine \textit{symbol-manipulierende Einrichtung} (enthält Symbole, die zusammen Symbolstrukturen bilden, welche erschaffen, bearbeitet, kopiert und gelöscht werden können. Beispiele: \textbf{Turingmaschine}, Universalrechner). Es muss in eine externe Umgebung eingebettet sein, damit man sein Verhalten evaluieren kann.

Beispiel Schach: Unser Schachbrett ist die \textit{planning domain}. In dieser domain kann man sich nur über Züge von Figuren, die Positionen auf dem Brett und ob das Spiel gewonnen oder verloren ist unterhalten. Unsere KI repräsentiert ihre Erkenntnisse als Objekte in dieser domain.

%https://en.wikipedia.org/wiki/Blocks_world

\subsubsection{3. Definitionsversuch}

KI ist das Unterfangen, ein PSS zu bauen, das den Turing-Test zuverlässig besteht.
Zusatzanforderung mancher KI-ler: Die von dem PSS manipulierten Symbole sollen Objekten in der eingebetteten Umgebung entsprechen.

\begin{definition}{Annahme des Deklarativismus.}

    Nach der Annahme des Deklarativismus kann ein System, das alle "intelligenten Antworten" in einer Tabelle nachschlägt, nicht intelligent sein.
\end{definition}

\begin{remark}
    Ein neuronales Netz ist keine deklarativistische Teildisziplin. Außer wenn man so viele Neuronen anlegst, dass alle Beispiele "gemerkt" werden können $\Rightarrow$ \textit{overfitting}.  
\end{remark}


\begin{remark}{Kann eine KI stark sein, wenn man auf einem Von-Neumann-Rechner ist?}
    Wahrscheinlich nein, weil er deterministisch ist.
\end{remark}

\subsubsection{Modellierungsansatz}

\begin{enumerate}
    \item Algorithmische Theorie (Problemstellung definieren, Beweis der algorithmischen Lösbarkeit)

    \item Repräsentation und Algorithmus (Algorithmus abstrakt entwerfen. Mithilfe eines Modells, z.B. Von-Neumann-Rechner, geeignete Datenstrukturen wählen)

    \item Implementation (Umsetzung in einer Programmiersprache bzw. Maschinenanweisungen, Optimierung)
\end{enumerate}

Kompetenz: 1. und 2.

Performanz: 2. und 3.

\subsubsection{Wissensbasierte Systeme}

Ein wissensbasiertes System kann als eine besondere Art von Programmiersystemen angesehen werden. Die Inferenzmaschine ist dabei ein Berechnungsmechanismus für mit der Wissensbasis gegebene Programme. Durch die Eingabe von Wissen wird die Inferenzmaschine programmiert. Das Wissen wird deklarativ repräsentiert. Es besteht sowohl aus Faktenwissen (ähnlich den Daten in einer herkömmlichen Datenbank) als auch Regelwissen, zum Beispiel in Form von Produktionsregeln (wenn ..., dann ...), die symbolisch vorliegen. 

Quelle: \href{https://de.wikipedia.org/wiki/Wissensbasiertes_System}{Wikipedia: Wissensbasiertes System}

\pagebreak

\begin{itemize}
    \item methodischer Aspekt -- automatische Lösung mit Fachwissen
    \begin{itemize}
        \item können mithilfe der Ableitungsregeln und dem Wissen in der WB schlussfolgern
    \end{itemize}
    \item qualitativer Aspekt -- schwieriges Problem
    \begin{itemize}
        \item WB-Systeme werden in Feldern angewendet, auf denen imperative, algorithmische Lösung schwer realisierbar sind
    \end{itemize}
    \item teleologischer Aspekt -- praktische Bedeutung
    \begin{itemize}
        \item 
    \end{itemize}
\end{itemize}

Ein WB-System benötigt explizit und deklarativ dargestelltes fachgebietsspezifisches Wissen, das nach generellen Prinzipien strukturiert ist und einen generellen Schlussfolgerungsmechanismus.

\subsubsection{Entwurf}
\begin{itemize}
    \item Wissensdarstellung ("Knowledge Representation")
    \item Wissensausnutzung ("Problem Solving")
    \item Wissenserwerb ("Knowledge Acquisition") $\rightarrow$ Erweiterung / Veränderung der WB
    \item Wissenstransfer, Erklärung ("Explanation")
\end{itemize}

\subsubsection{Wissensrepräsentation}
\paragraph{Wissenstypen}

\begin{itemize}
    \item elementare Tatsachen, Schlussweisen
    \item spezielle Fälle, Situationen
    \item bestimmte Vorgehensweisen, Algorithmen
    \item allgemeine Gesetzmäßigkeiten, Alltagswissen
\end{itemize}

\subsubsection{Logik-basierte Repräsentationsformalismen}
\begin{itemize}
    \item Terminologische Logiken, Beispiel: Diagnosesystem für Fahrzeugdefekte. Symptome als Input, Diagnose als Output)
    \item Vererbung (von Eigenschaften)
    \item Nicht-Monotonie (Monotonie bedeutet, dass bei Erweiterung der Wissensbasis alle bisherigen Schlüsse weiterhin gültig sind. Verwendung von Defaults ist bspw. nicht-monoton.)
\end{itemize}

\subsubsection{Problemlösungstechniken in WB-Systemen}

\begin{description}
    \item[Klassifikation] ...
    \item[Zugriff] ...
    \item[Synthese] Schließen von neuem Wissen aus der bestehenden WB (und anschließendes Aufnehmen in die WB)
    \item[Deduktion] Ableitung mithilfe von Ableitungsregel
    \item[Simulation] ...
    \item[Zielorientierte Suche] ...
    \item[Planen als zielorientierte Suche auf Metaebene] 
    \item[Strukturanalyse] ...
    \item[Transformation] ...
\end{description}

\subsubsection{Einsatzbereiche für WB-Systeme}
\begin{itemize}
    \item Interpretation physikalischer Daten (Messungen interpretieren)
    \item Diagnose von Systemzuständen (Fehler im Auto, kranker Patient)
    \item Planung von Handlungen, um Ziele zu erreichen (Marjapussi)
    \item Entwurf und Konstruktion nach Spezifikation 
    \item Unterricht und Training von Kenntnissen und Fähigkeiten (Deep Learning?)
\end{itemize}

\subsection{Wichtige Teilgebiete der KI}

\subsubsection{Klassische (symbolische) KI}

Die klassische KI nutzt zur Problemlösung Repräsentation für Probleme in (menschenlesbaren) Hochsprachen. Sie nutzt logische Programmierung, Produktionsregeln, semantische Netze und \textit{frames}. Aus ihr entstanden Anwendungen wie Expertensysteme (wissensbasierte Systeme) und automatische Beweisprogramme.

\begin{itemize}
    \item Wissensrepräsentation
    \item Heuristische Suchverfahren
    \item Planung
    \item Wahrnehmung
    \item Deduktion
    \item Lernen
    \item Sprach- und Bildverarbeitung
    \item Verarbeitungsmodelle, KI-Programmiersprachen
\end{itemize}

\subsubsection{Konnektionismus (Soft Computing)}

ist ein Teilgebiet der Kybernetik, welches sich mit dem Verhalten vernetzter Systeme basierend auf Zusammenschlüssen von künstlichen Informationsverarbeitungseinheiten beschäftigt. \textbf{Soft Computing} befasst sich mit der approximativen Lösung. \textit{Es ist von numerischen Verfahren zu unterscheiden.}

\begin{description}
    \item[ Neuronale Netze]
    \item[ Genetische Algorithmen ] (In Anlehnung an die Natur: Suche nach Lösungen mit stochastischen Optimierungsverfahren)
    \item[ Fuzzy Logic ] (Verallgemeinerung der zweiwertigen Booleschen Logik - erlaubt bspw. die Beschreibung der Ausprägung einer Eigenschaft)
\end{description}

\subsubsection{Hybride}

\begin{itemize}
    \item 
\end{itemize}

\section{Logik}


\textbf{TODOs}
\begin{itemize}
    \item Interpretationsbereich klären (Seite 5 lprelim.div)
\end{itemize}

\subsection{Lernfragen}

\begin{description}
    \item[Logische Programmierung] Besteht aus einer Menge von Axiomen, die als Fakten oder Annahmen zu verstehen sind, aus denen die Anfrage eines Benutzers beantwortet werden soll. 
    \item[Aussagenlogik] Atome (denen ein Wahrheitswert zugeordnet wird) und Junktoren
    \item[Prädikatenlogik] Erweitert um Prädikate (Aussagen mit Leerstellen, wie eine Funktion) und Quantoren ($\exists, \forall$). Bspw. $\forall x \in \text{Menschen}: \text{mutter}(\text{Eva}, x)$
    \item[Klausellogik] Formel in KNF, bei der die Konjunktionen jeweils in Mengenschreibweise zusammengefasst werden. Bspw.: \\
    $((a \lor b) \land (b \lor c) \land (a \lor \lnot d \lor \lnot e) \land d) \estimates \{\{a,b\}, \{b, c\}, \{a, d, e\}, \{d\}\}$
    \item[Aussagenlogische Resolution] Statt eine allgemeine Gültigkeit zu beweisen, leitet es einen Widerspruch für die Negation her    
    \item[Unifikation] Zwei Ausdrücke werden unifiziert, indem ihre Variablen so durch geeignete Terme ersetzt werden, dass die resultierenden Ausdrücke gleich sind.
    \item[Prädikatenlogische Resolution] Zwei Klauseln $K$ und $K'$ werden resolviert, indem man man ein $\phi$ findet, das in $K$ enthalten ist und dessen Negation $\lnot\phi \in K'$. Man bildet dann die Vereinigung $(K \backslash \phi) \cup (K' \backslash \lnot\phi)$ und nennt sie Resolvente.
    \item[Aussagenlogische Resolution] Exakt analog zu prädikatenlogischer Resolution. Man nimmt den Term und seine Negation aus den zu resolvierenden Klauseln und bilden ihre Vereinigung.
    \item[Inferenz] aufbereitetes Wissen, das aufgrund von logischen Schlussfolgerungen gewonnen wurde
\end{description}

\subsection{Logische Programmierung}
\begin{itemize}
    \item Mit Logik lässt sich Wissen formalisieren
    \item Die \textbf{Prädikatenlogik} 1. Stufe (PL1) die bekannteste Logik
    \item Inferenzmechanismen gestatten es, aus "altem" (explizitem) Wissen, "neues" (implizites) Wissen abzuleiten.
\end{itemize}

Die Klausellogik als syntaktische Teilklasse von PL1 ist für das Theorembeweisen von besonderer Wichtigkeiten

Der auf Klausellogik basierende Resolutionskalkül kann aber auch als \textbf{Programmiersprache} verwendet werden.

Logische Programmierung (z.B. in \textbf{Prolog}) basiert auf \textbf{Klausellogik} und dem Standard-Inferenzmechanismus der \textbf{Resolution}. Prolog ist daher ein \textit{Satisfiability Solver}. Statt Prolog ließe sich eine prädikatenlogische Axiomensammlung auch mit einem anderen SAT-Solver lösen -- der Vorteil besteht darin allerdings in der Einfachheit des Backtracking-Algorithmus. Er besitzt ein vom Programmierer reproduzierbares und planbares Verhalten. 

\[
    \text{Annahmen} \xrightarrow[\text{als Inferenzregel}]{\text{Resolution}} \text{Konklusionen}
\]

% TODO Beispiel in PROLOG

\subsection{Syntax der Prädikatenlogik}

Induktiver Aufbau prädikatenlogische Ausdrücke mit:

\begin{enumerate}
    \item \textbf{Konstantensymbolen} $a, b, c, \dots$
    \item \textbf{Funktionssymbolen} $f, g, h, \dots$
    \item \textbf{Variablensymbolen} $x, y, z, \dots$
    \item \textbf{Prädikatensymbolen} likes, father, $\dots$
\end{enumerate}

Man unterscheidet zwischen \textit{Termen, Atomformeln}.
Ein \textbf{Term} ist entweder

\begin{itemize}
    \item ein Konstantensymbol,
    \item ein Variablensymbolen
    \item ein Funktionssymbol angewendet auf ein Tupel (geordnete Anordnung) von Termen.
\end{itemize}

Eine \textbf{Atomformel} ist ein Prädikatsymbol, angewendet auf ein Tupel von Termen.

Ein \textbf{Grundterm/Grundformel} ist ein Term/eine Formel, der/die keine Variablen enthält.

\begin{example}
    $a, x$ und $f(b, f(b, y, z), y)$ sind Terme.\\
    $\text{likes}(x, \text{dad}(x))$ und \\
    $\text{borrows}(\text{doug}, \text{book}, \text{chris})$ sind Atomformeln.
\end{example}

Eine \textbf{wohlgeformte Formel} ist entweder eine Atomformel oder hat eine der folgenden Formen $(W_1, W_2, W \text{ seien wohlgeformt}):$

\begin{align}
    (W) \\
    W_1 \land W_2 \\
    W_1 \rightarrow W_2 \\
    \lnot W \\
    W_1 \lor W_2 \\
    (\exists X) W \\
    (\forall X) W
\end{align}

Der \textbf{Gültigkeitsbereich} einer Quantifikation $\forall x$ (bzw. $\exists x$) in einer Formel $\forall x \text{F}$ (bzw. $\exists x \text{F}$) ist genau die Teilformel F. Die Variable $x$ heißt dann \textbf{gebunden} in $\forall x \text{F}$ (bzw. $\exists x \text{F}$).

Eine Variable, die in keiner Teilformel einer Formel F gebunden auftritt, heißt \textbf{frei} in F.

Eine \textbf{geschlossene Formel} ist eine wohlgeformte Formel, in der jedes Vorkommen eines jeden Variablensymbols gebunden ist.

\begin{example}
    $(\forall x)((\exists y) \text{child}(x) \rightarrow \text{father}(y, x)).$
\end{example}

Bindungsregeln der logischen Konnektoren und Quantoren:

\setlength{\tabcolsep}{12pt}
\begin{center}    
    \begin{tabular}{l l l}
        $\lnot$           & bindet stärker als & $\land$ und $\lor$ \\
        $\land$ und $\lor$ & bindet stärker als & $\rightarrow$
    \end{tabular}
\end{center}

\subsection{Prädikatenlogik -- die Semantik}

Die Bedeutung einer logischen Sprache wird mithilfe einer \textbf{Interpretation $I$} festgelegt:

\begin{enumerate}
    \item Der \textbf{Interpretationsbereich} $D = dom(I)$ ($dom \estimates$ \href{https://en.wikipedia.org/wiki/Domain_of_discourse}{domain of discourse}) ist eine (nichtleere) Menge von Objekten, auf die sich $I$ bezieht.
    \item Jedem Konstantensymbol wird genau ein Element aus $D$ zugeordnet.
    \item Jedem $n$-stelligen Funktionssymbol wird genau eine Funktion von $D^n \mapsto D$ zugeordnet.
    \item Jedem $n$-stelligen Prädikatsymbol wird genau eine $n$-stellige Relation aus $dom(I)^n$ zugeordnet.
\end{enumerate}
Eine Interpretation weist jeder Formel $G$ einen Wahrheitswert zu:
% TODO weist eine Interpretation einer Formel wirklich einen Wahrheitswert zu?

\begin{itemize}
    \item $I \vDash G$, wenn $I$ der Formel $G$ den Wert \textbf{wahr} zuordnet und
    \item $I \nvDash G$, falls $I$ der Formel $G$ den Wert \textbf{falsch} zuordnet.
\end{itemize}

\subsection{Wahrheitswert zusammengesetzter Formeln}

Prinzip der \textbf{Kompositionalität}:

Der Wahrheitswert einer Formel setzt sich aus den Wahrheitswerten ihrer Teilformeln zusammen.

\begin{center}
    \begin{tabular}{l l l l}
        $\lnot W$ & wahr & $\Leftrightarrow$ & $W$ falsch \\
        $W_1 \land W_2$ & wahr & $\Leftrightarrow$ & $W_1$ wahr und $W_2$ wahr \\
        $W_1 \lor W_2$ & wahr & $\Leftrightarrow$ & $W_1$ wahr oder $W_2$ wahr \\
        $W_1 \rightarrow W_2$ & falsch & $\Leftrightarrow$ & $W_1$ wahr und $W_2$ falsch
    \end{tabular}
\end{center}

$(\forall x) W$ ist wahr gdw. für \textbf{jedes} Element $e$ aus $\mathcal{D}$, durch Ersetzen der Variablen $x$ durch $e$ eine wahre Formel entsteht, sonst falsch.

$(\exists x) W$ ist wahr gdw. für \textbf{ein} Element aus $e$ aus $\mathcal{D}$, durch Ersetzen der Variablen $x$ durch $e$ eine wahre Formel entsteht, sonst falsch.

\subsection{Begriffe aus der Modelltheorie}

\subsubsection{Modelltheorie}
Inhalt der Modelltheorie sind die Beziehungen zwischen den rein formalen Ausdrücken einer Sprache (syntaktische Ebene) und deren Bedeutung (semantische Ebene). Diese Beziehung wird über sogenannte Interpretationen und eine als Erfüllungsrelation bezeichnete mathematische Relation hergestellt.

Gibt es für eine Formel $F$ eine Interpretation $\mathcal{I}$, die $F$ wahr macht, so heißt $F$ \textbf{erfüllbar} und $\mathcal I$ ein Modell für $F$. \\

Eine Formel $F$ heißt \textbf{gültig}, falls sie in jeder Interpretation wahr ist. Schreibweise $\vDash F$. \\
% TODO ist das wirklich in JEEEEDDDEEEER Interpretation so???

Ist eine Formel $F$ in keiner Interpretation wahr, so nennen wir sie \textbf{unerfüllbar}. \\

Sei $\Gamma$ eine Menge geschlossener Formeln und $F$ eine beliebige geschlossene Formel. $F$ heißt \textbf{logische Konsequenz} von $\Gamma$,

\[
    \Gamma \vDash F,
\]

falls für jede Interpretation $\mathcal I$ gilt:

\[
    \text{falls } \mathcal I \vDash \Gamma, \text{ dann } \mathcal I \vDash F.
\]

Es gilt damit:

\[
    \Gamma \cup \{\lnot F\} \text{ ist unerfüllbar gdw. } \Gamma \vDash F.
\]

Dies impliziert, dass eine Menge an Formeln $\Gamma$ erfüllbar ist gdw. alle Formeln in $\Gamma$ erfüllbar sind.

Daher kann man sich beim Beweis der \textbf{logischen Konsequenz} mit dem Nachweis der entsprechenden \textbf{Unerfüllbarkeit} behelfen.

\begin{example}
    Seien in einer Sprache $c_i$ Konstantensymbole, $f_i$ Funktionssymbole, $R_i$ Prädikatensymbole, $x_i$ Variablensymbole.
    %
    Gegeben seien weiter die Interpretationen $I_1$ und $I_2$:

    \begin{tabular}{L L L L l}
        I_1: & dom(I_1) & \mapsto & \mathcal N & Domäne der natürlichen Zahlen \\
             & c_1      & \mapsto & 0          & Konstantensymbol \\
             & f_1^1    & \mapsto & succ       & einstelliger Nachfolgerfunktion \\
             & R_1^1    & \mapsto & =          & zweistelliges Gleichheitsprädikat \\
             \\
        I_2: & dom(I_1) & \mapsto & \mathcal Q & Domäne der positive rationalen Zahlen \\
             & c_1      & \mapsto & 1          & Konstantensymbol \\
             & f_1^1    & \mapsto & id         & einstellige Identitätsfunktion \\
             & R_1^2    & \mapsto & \leq       & zweistelliges kleiner-oder-gleich-Prädikat
    \end{tabular}
    \\
    Die Formel 
    \[
        P = (\forall X_1) R_1^2(f_1^1(f_1^1(x_1)), x_1)
    \]
    bedeutet im Falle der Interpretation

    \begin{center}
        \begin{tabular}{L l L}
            I_1: & für jedes $x \in \mathcal N$ gilt: & succ(succ(x)) = x \\
            I_2: & für jedes $x \in \mathcal Q$ gilt: & id(id(x)) \leq x
        \end{tabular}
    \end{center}
    %
    Die Aussage $P$ ist
    \begin{enumerate}
        \item für $I_1$ falsch ($I_1 \nvDash P)$,
        \item für $I_2$ dagegen wahr ($I_2 \vDash P)$.
    \end{enumerate}
\end{example}

\subsection{Begriffe aus der Beweistheorie}

\subsubsection{Beweistheorie}
ist ein Teilgebiet der mathematischen Logik, das Beweise als formale mathematische Objekte behandelt, was deren Analyse mit mathematischen Techniken ermöglicht. Beweise werden üblicherweise als induktiv definierte Datenstrukturen dargestellt, wie Listen oder Bäume. Diese werden gemäß den Axiomen und Schlussregeln des betrachteten logischen Systems konstruiert. Die Beweistheorie ist von syntaktischer Natur im Gegensatz zur Modelltheorie, die von semantischer Natur ist. 

\textbf{Beweisen} ist syntaktisches Folgern
\begin{itemize}
    \item in einer Sprache $L$
    \item mit vorgegebenen \textbf{Schlussregeln} $R$:
\end{itemize}

\[ \vdash_{L,R}\; := \{(S, s) \, |\, S \subset L, s \in L, S \vdash_{L,R} s\} \]
%
Im logisches Kontext bezeichnet man
\begin{itemize}
    \item die Ausgangssätze als \textbf{Axiome},
    \item die abgeleiteten Sätze als \textbf{Theoreme},
    \item die Ableitungsregeln $R$ als \textbf{Inferenzregeln}.
\end{itemize}
%
\textbf{Ableitungen} sind endliche Folgen
\[ \langle s_1, \dots, s_n\rangle \]
mit
\[ \{s_i \, |\, i < j\} \vdash s_j \]
(für $j \leq n$).
Für jedes Axiom $A$ gilt dann $\emptyset \vdash A$. $S$ stellt unsere bisherige Wissensbasis dar.

In der Logikprogrammierung sind die Axiome üblicherweise \textbf{nicht-logische Hypothesen:}
\begin{itemize}
    \item Die Hypothesen drücken Annahmen über den Problembereich aus.
    \item Aus den Hypothesen ableitbare Sätze sind \textbf{nicht-logische Theoreme}.
\end{itemize}
%
Probleme, die mit Logikprogrammiersystemen gelöst werden, sind von der Gestalt:
\begin{itemize}
    \item Gegeben sei eine Menge $S$ von Annahmen.
    \item Gesucht sind Sätze $s$, die syntaktische Konsequenzen dieser Annahmen beschreiben: $S \vdash s$.
\end{itemize}
%
Dabei soll gelten: Falls $S$ die Annahmen \textbf{korrekt} beschreibt, dann drückt $s$ eine Konsequenz ebenfalls korrekt aus.

Was hier \textbf{Korrektheit} bedeutet, legt die intendierte \textbf{Interpretation  $\mathcal I$} des Logikprogrammierers fest.


Für $I$ soll gelten:

\[ \text{Falls } I \vDash S \text{ und } S \vdash s, \text{ dann } I \vDash s \]

\subsubsection{Korrektheit der Inferenzregeln}
\[ \Gamma \vdash F \Rightarrow \Gamma \vDash F \]

\parindent 0mm
Korrekte Inferenzregeln sind etwa
\begin{description}
    \item[modus ponens:] $B, B \rightarrow A \vdash A$
    \item[modus tollens:] $\lnot A, B \rightarrow A \vdash \lnot B$ 
\end{description}

\subsubsection{Vollständigkeit der Inferenzregeln}
\[ \Gamma \vDash F \Rightarrow \Gamma \vdash F \]

Für korrekte und vollständige Inferenzsysteme fallen syntaktischer und semantischer Ableitungsbegriff zusammen:

\[ \Gamma \vdash F \Leftrightarrow \Gamma \vDash F \]

Der in \textsc{Prolog} verwendete \textbf{Resolutionskalkül}
\begin{itemize}
    \item basiert auf nur einer (korrekten) Inferenzregel und
    \item ist nur auf Formeln einer speziellen syntaktischen Form, der \textbf{Klauselform}, anwendbar.
\end{itemize}

\subsection{Klausellogik}

Ein \textbf{Literal} ist entweder eine atomare Formel (positives Literal) oder eine negierte atomare Formel (negatives Literal). (Atomare Formel bzw. Atomformeln sind Prädikatensymbolen, angewendet auf ein Tupel von Termen.)

\begin{example}
    \[ \text{likes}(chris, mummy), \quad \lnot\text{likes}(chris, suffering) \]
\end{example}

Eine \textbf{Klausel} ist eine Formel der Form $\langle\text{Präfix}\rangle\langle\text{Matrix}\rangle$


\begin{tabular}{l l}
    \textbf{Präfix}: & Sequenz von All-Quantifizierungen. \\
    \textbf{Matrix}: & Quantorenfreie Konjunktionen von Formeln, \\
                     &  die wiederum nur aus Disjunktionen von Literalen \\
                     & zusammengesetzt sein dürfen.    
\end{tabular}

\begin{example}
    \begin{align*}
        (\forall x\forall y)( &(\text{likes}(chris, x) \lor \lnot \text{likes(x, logic)})\; \land \\
        & \text{likes}(chris, logic)\; \land \\
        & \text{likes}(bob, logic)\; \land \\
        & (\text{likes}(x,y) \lor \lnot \text{loves}(x, y)))
    \end{align*} ist eine 
    Dies ist eine Menge sogenannter definitver Klauseln.
    Lässt man hier die Quantoren weg (implizite All-Quantifizierung), ersetzt $\lor\lnot$ durch \texttt{:-} und schreibt alle Variablen groß, so erhält man ein \textsc{Prolog}-Programm.
\end{example}

Eine \textbf{definite Klausel} enthält genau ein positives Literal und beliebig viele negative Literale.

\section{Suche}

\subsection{Prüfungsfragen}
\begin{description}
    \item[Zustandsraum] Baum mit Knoten, die Zustände der Suche beschreiben. 
    \item[Suche in Zustandsräumen] 
    \item[Zustandsraumrepräsentationen] 
    \item[Blinde Suche] 
    \item[Heuristische Suche]
    \item[Vorwärts- und Rückwärtssuche]  
\end{description}

\subsection{Zustandsraum}
\begin{itemize}
    \item Baum mit Knoten, die Zustände
    \item Wurzel ist Startzustand. 
    \item Es gibt mindestens einen Zielzustand.
\end{itemize}

\subsection{Suche in Zustandsräumen}
\textbf{Die Suchprozedur}

\textbf{Eingabe:}
\begin{enumerate}
    \item Startknoten (Plural)
    \item Zielknoten (Plural)
    \item Funktion, die Nachfolger zu einem Knoten generieren kann (das Erweitern um einen Knoten nennt man expandieren)
    \item eventuell Qualitätskriterien
\end{enumerate}

\textbf{Ausgabe:} Den Pfad vom Startzustand zu einem Zielzustand. \\

Der Suchraum besteht zu Beginn des Suchverfahrens nicht. Der Suchraum wächst mit jeder Ebene im Baum exponentiell. Deshalb generiert man den Suchbaum soweit nötig während der Suche. Einerseits ist dies durch den Speicherbedarf und andererseits durch die Berechnung einer Modifikation limitiert. Innere Knoten entsprechen partiellen Lösungen. Blätter im voll expandierten Suchraum sind nicht-expandierbare Knoten.

\textbf{Generische Prozedur zum Lösen von Suchprobleme:}
\begin{enumerate}
    \item Sei $L$ die Liste der Startknoten (unser Suchproblem kann daher ein Wald sein) für das Problem (ab jetzt wird $L$ immer die Liste der noch nicht überprüften Knoten darstellen). 
    \item Ist $L$ leer, so melde einen Fehlschlag. \\
          Andernfalls wähle einen Knoten $n$ aus $L$.
    \item Stellt $n$ einen Zielknoten dar, so melde Erfolg und liefere den Pfad vom Startknoten zu $n$.
    \item Andernfalls ersetze in $L$ den Knoten $n$ durch seine Nachfolgeknoten\\
          Markiere dabei die neuen Knoten mit dem jeweils zugehörigen Pfad vom Startknoten. (Markieren kann mit einer sogenannten Closed-List /-Set umgesetzt werden. Knoten werden markiert, indem man sie dort einfügt.)
    \item Weiter mit Schritt $2! = 2$.
\end{enumerate}

Das bedeutet: Knoten werden erst beim Expandieren auf Zieleigenschaft überprüft.

Die Art der Wahl in Schritt $2!$ bestimmt die Suchstrategie:
\begin{itemize}
    \item \textit{blind:} Wahl allein aufgrund von \textit{Position im Baum} $\rightarrow$ bspw. Tiefen- und Breitensuche.
    \item \textit{heuristisch:} Wahl unter \textit{Berücksichtigung der Domäne} $\rightarrow$ bswp. Suchverfahren mit einer Auswahlfunktion die Inhalte der Knoten einfließen lässt.
\end{itemize}

\subsection{Tiefensuche}

\begin{enumerate}
    \item Sei $L$ die Liste der Startknoten für das Problem.
    \item Ist $L$ leer, so melde einen Fehlschlag. \\
          Andernfalls wähle den \textit{ersten} Knoten $n$ aus $L$.
    \item Stellt $n$ einen Zielknoten dar, so melde Erfolg und liefere den Pfad vom Startknoten zu $n$.
    \item Andernfalls entferne $n$ aus $L$ und füge seine Nachfolgeknoten \textit{am Anfang} von $L$ an. \\
          Markiere dabei wieder die neuen Knoten mit dem jeweils zugehörigen Pfad vom Startknoten.
    \item Weiter mit Schritt $2!$.
\end{enumerate}

\subsection{Breitensuche}
$\dots$ genau der gleiche Algorithmus wie oben, nur dass man im Schritt 4 die Nachfolgeknoten \textit{am Ende} von $L$ anfügt.

\subsection{Tiefen- vs. Breitensuche, informell}

Suche, die \textit{schnell bei Endzuständen} ankommt ist \textit{speicherökonomisch}:
\begin{indentleft}{1cm}
    Allein die Endzustände sorgen für Verkleinerung der Liste $L$ (der momentan gespeicherten Knotenmenge). Denn Eltern, die ausschließlich Endzustände als Kinder besitzen, können verworfen werden.
\end{indentleft}

Daher ist typischerweise Tiefensuche weniger speicherintensiv. Jedoch bestimmt die Form des Suchraums, welche Strategie besser ist.

Breitensuche ist besser, falls:
\begin{enumerate}
    \item niedriger Verzweigungsgrad
    \item Lösung auf geringer Tiefe
\end{enumerate}

Tiefensuche terminiert nicht, falls es unendlich lange Wurzelpfade gibt (wir beliebig tief expandieren können bzw. der Suchraum unendlich groß ist).

\subsection{Heuristische Suche}

Da wir bei Suchproblemen in der Praxis niemals den vollständigen Suchraum aufstellen, geschweige denn speichern können, benötigen wir eine Funktion, die die Entfernung zum Zielknoten schätzt.
\\
\\
Die heuristische Funktion bestimmt einen möglichst guten als nächsten zu expandierenden Knoten. (Sie nimmt als Eingabe einen Knoten und liefert als Ausgabe einen geschätzten Abstand zum Ziel.)
\\
\\
Beste Heuristik = teuerste Heuristik! (man könnte den gesamten Suchraum zur Bestimmung des optimalen nächsten Knotens bestimmen)
\\
\\
Wir nennen das Berechnen der Heuristikfunktion für alle Knoten im Saum \textit{Meta-level Aktivität} und das Ausführen einer Modifikation \textit{Base-level Aktivität}.
\\
\\
Aufwand auf dem Meta-level muss sich auf dem Base-level bezahlt machen! (Bei blinder Suche ist unser ML-Aufwand $ = 0$.)

\subsection{Vorwärts- und Rückwärtssuche}

Man kann die Suche auch umkehren, sofern die Modifikation umkehrbar und eine Lösung explizit (nicht nur implizit bspw. Kreuzworträtsel) bekannt ist. Wenn der Eingangsgrad größer ist als der Ausgangsgrad, so ist Rückwärtssuche einfacher ($\rightarrow$ man kehrt das Suchproblem um). Dadurch ist die Anzahl der Nachfolger geringer, damit auch die Anzahl an notwendigen Expansionen und auch der Rechenaufwand.

% TODO Prüfen, was damit gemeint ist
Unser Framework ermöglich bis jetzt nur Vorwärtssuche (wir können \textit{nur Nachfolger} generieren).

Abhilfe:
\\
\begin{indentleft}{1cm}
    Statt eines \textit{Suchbaums} verwenden wir einen \textit{Suchgraphen} zur Beschreibung des Suchraums.
\end{indentleft}

Mischformen sind ebenfalls möglich: man teilt das Suchproblem in Teilprobleme auf und kann in diesen wahlweise vorwärts oder rückwärts suchen.

\begin{example}
    \begin{itemize}
        \item Kannibalen und Missionare (zwei Uferseiten und ein Boot. Auf keiner der Seiten dürfen mehr Kannibale sein als Missionare $\rightarrow$ Constraints)
    \item Türme von Hanoi (Constraints: man darf immer nur eine Scheibe bewegen. Eine größere darf nicht auf einer kleineren Liegen.)
    \item n-Damen-Problem (Damen dürfen sich auf einem $n\times n$-Schachfeld nicht gegenseitig schlagen können)
    \item 8-Puzzle
    \end{itemize}
\end{example}

$\hookrightarrow$ Constraints verkleinern den Suchraum erheblich!

\subsection{Crux der blinden Suche}

Blinde Suchverfahren sind praktisch nicht einsetzbar. Sie benötigen:

\[ Time(X) = \mathcal O(b^d) \]

Sie müssen im Worst-Case den gesamten Suchraum durchlaufen. Dieser wächst exponentiell.

Daher benötigen wir Verfahren, mit denen wir spezifisch für das gegebene Problem die nächsten zu expandierenden Knoten bewerten können. Die optimale Wahl \textit{sicherzustellen} ist genau so teuer wie \textit{blinde Suche}. Wir suchen daher eine Daumenregel (eine sogenannte Heuristik) zur \textit{Abschätzung} $h$ des echten Abstands $h^*$ zum Ziel.

\begin{example}
    8-Puzzle (mit Zahlen). Als Heuristik wählt man die Anzahl an fehlplatzierten Steinen oder die Manhattan-Distanz.
\end{example}

\subsection{Hill Climbing mit Rücksetzen (BTHC)}

\begin{enumerate}
    \item Sei $L$ die Liste der Startknoten für das Problem, \textit{sortiert} nach der jeweils geschätzten Distanz $h$ zum ziel.
    \item Ist $L$ leer, so melde einen Fehlschlag. \\ Andernfalls wähle den \textit{ersten} Knoten $n$ aus $L$.
    \item Stellt $n$ einen Zielknoten dar, so melde Erfolg und liefere den Pfad vom Startknoten zu $n$.
    \item Andernfalls entferne $n$ aus $L$ und füge seine Nachfolgeknoten, sortiert nach der jeweils geschätzten Distanz $h$ zum Ziel, \textit{am Anfang} von $L$ an. \\ Markiere dabei die neuen Knoten mit dem jeweils zugehörigen Pfad vom Startknoten.
    \item Weiter mit Schritt $2$!
\end{enumerate}

Das ist effektiv Tiefensuche mit einer Heuristik (auch der Speicher- und Zeitbedarf ist vergleichbar). Wir wählen immer das am Besten bewertete Kind und expandieren es. (Eigentlich sortieren wir die Kinder des zuletzt expandierten Knoten nach der Schätzfunktion und fügen sie am Anfang der Openlist $L$ ein.)

\subsection{Striktes Hill Climbing}

\begin{enumerate}
    \item Sei $L$ die Liste der Startknoten für das Problem, \textit{sortiert} nach der jeweils geschätzten Distanz $h$ zum Ziel.
    \item Ist $L$ leer, so melde einen Fehlschlag. \\ Andernfalls wähle den \textit{ersten} Knoten $n$ aus $L$.
    \item Stellt $n$ einen Zielknoten dar, so melde Erfolg und liefere den Pfad vom Startknoten zu $n$.
    \item Andernfalls entferne $n$ aus $L$ und füge (nur) den besten Nachfolgeknoten von $n$ (den mit minimaler geschätzter Distanz $h$ zum Ziel) \textit{am Anfang} von $L$ an. \\ Markiere dabei den neuen Knoten mit dem zugehörigen Pfad vom Startknoten.
    \item Weiter mit Schritt $2$!
\end{enumerate}

SHC hat \textit{konstanten Speicherbedarf} falls der Ausgangsverzweigungsgrad des Suchbaums beschränkt ist:

\[ \text{Space}(SHC) = \mathcal O(d) \textcolor{gray}{\text{ im Skript steht } \mathcal O(b)} \]

\subsection{Best-First-Suche (BS)}
\begin{enumerate}
    \item Sei $L$ die Liste der Startknoten für das Problem.
    \item Ist $L$ leer, so melde einen Fehlschlag. \\ Andernfalls wähle denjenigen Knoten $n$ aus $L$, der dem Ziel \textit{schätzungsgemäß am nächsten} ist.
    \item Stellt $n$ einen Zielknoten dar, so melde Erfolg und liefere den Pfad vom Startknoten zu $n$.
    \item Andernfalls entferne $n$ aus $L$ und füge alle seine Nachfolgeknoten in die Liste $L$ ein. \\ Markiere dabei wieder die neuen Knoten mit dem jeweils zugehörigen Pfad vom Startknoten.
    \item Weiter mit Schritt $2$!
\end{enumerate}

Dieses Verfahren betrachtet den gesamten Saum. Wir nehmen aus allen Knoten in der Openlist den vielversprechendsten. BS ist \textit{wesentlich speicherintensiver} als HC, denn die Openlist kann sehr groß werden.

\subsection{Suche als Funktionsmaximierung}

Man kann Suche auch als Funktionsmaximierung sehen.

\begin{center}
    \begin{tabular}{l l}
        Gegeben: & eine Funktion $f$, die für einen Zustand $p$ dessen \textit{Interessantheit} $f(p)$ misst, \\
        gesucht: & das Maximum $\text{max}_p\, f(p)$
    \end{tabular}
\end{center}

\subsection{Probleme mit striktem (optimistischem) Hill Climbing}

Bei einem lokalen Maximum, das nicht unserem globalen Maximum (Zielzustand) entspricht gerät das strikte HC in eine Sackgasse ($\rightarrow$ der Algorithmus terminiert mit einem Fehlschlag, da kein BT möglich ist). Das Verlassen des lokalen Maximums setzt voraus, dass wir entgegen der Empfehlung der Heuristik das lokale Maximum verlassen.

Es wäre daher notwendig, den "Horizont zu erweitern". Dies kann einerseits durch einen randomisierten Anteil in der Heuristik oder das vorübergehende einsetzen von Breitensuche realisiert werden. (Hilft auch bei Plateaus. Denn HC würde ohne Heuristik in \text{genau eine} Richtung gehen und alles andere verwerfen. Er läuft damit Gefahr niemals zum Ziel zu kommen.)

Rubik's Cubes sind ein gutes Beispiel für den Einsatz von Makrooperatoren. Es ist sinnvoll mehrere Züge (Drehungen) zu einem Operator zusammenzufassen und diesen als Modifikation zu betrachten (bspw. das Vertauschen zweier Steine).

\subsection{Simulated Annealing}

Ebenfalls HC, wobei man mit einer bestimmten Wahrscheinlichkeit $p$ (proportional zu einer globalen Größe $T$) ein Schritt in eine Richtung unternommen wird, der \textit{keine Minimierung der geschätzten Distanz} $h$ bewirkt. Diese Wahrscheinlichkeit wird mit jeder Iteration langsam reduziert.

$\Rightarrow$ lokale Maxima können wieder verlassen werden (ein hohes initiales $T$ vorausgesetzt)

\section{A-Algorithmus}

$\dots$ die Antwort drauf, dass sowohl HC als auch BS nicht immer \text{eine beste Lösung} finden

\begin{center}
    \begin{tabular}{c c c}
        \huge Güte einer Lösung & \huge $\thicksim $ & \huge Tiefe im Suchraum \\
        & & (je kleiner, desto besser)        
    \end{tabular}
\end{center}

HC und BS sind gierige Suchverfahren und finden bei einer (einmalig oder partiell) ungenauen Heuristik keine optimale Lösung. Bei einer perfekten Heuristik finden sie die optimale (aber BL- und ML-Aufwand müssen im Verhältnis stehen). 

Expandiere den Knoten $n$ zuerst, der \textit{schätzungsgemäß am nächsten} $(h)$ an einem hochliegenden $(d)$ Ziel liegt, d.h. den mit \textit{minimalem} $f(n) := d(n) + h(n)$.

Im Allgemeinen setzt man statt $d$ die Schätzung $g(n)$ der tatsächlichen Kosten $g^*(n)$, die man benötigt, um $n$ zu erreichen.

\pagebreak

\subsection{Der Algorithmus}

\begin{enumerate}
    \item Sei $L$ die Liste der Startknoten für das Problem.
    \item Ist $L$ leer, so melde einen Fehlschlag. \\ Andernfalls wähle denjenigen Knoten $n$ aus $L$, für den \\
    \[ f(n) = g(n) + h(n) \]
    \textit{minimal} ist.
    \item Stellt $n$ einen Zielknoten dar, so melde Erfolg und liefere den Pfad vom Startknoten zu $n$.
    \item Andernfalls entferne $n$ aus $L$ und füge alle seine Nachfolgeknoten in die Liste $L$ ein. Markiere dabei die neuen Knoten mit dem jeweils zugehörigen Pfad vom Startknoten.
    \item Weiter mit Schritt $2$!
\end{enumerate}

Im Prinzip Best-First Suche mit $f$ statt $h$.

\subsection{Der $A^*$-Algorithmus}

$h$ ist \textit{optimistisch} (zulässig), falls: \qquad $\forall n: h(n) \leq h^*(n)$\\
(falls also nicht überschätzt wird)

\large Der $A$-Algorithmus wird für zulässiges $h$ zum $A^*$-Algorithmus!

\subsubsection{Eigenschaften des $A^*$-Algorithmus}

\begin{figure}
    \begin{center}
        \includegraphics[width=8cm]{a_stern_argument_grafik.jpg}
    \end{center}
    \caption{$A^*$-Algorithmus findet immer das Optimum}    
\end{figure}

Je tiefer der Pfad, desto größer wird $f(n) = g(n) + h(n)$, da $g(n)$ überschätzt und $h(n)$ unterschätzt. Also sind die geschätzten Kosten am Anfang immer geringer als die tatsächlichen Kosten am Ende des Pfades. Somit kann ein gefundener Zielpfad nur der Beste sein, denn gäbe es einen noch besseren Pfad, so wäre dessen Schätzung $h$ noch besser gewesen und wir hätten an irgendeinem Punkt in diese Richtung exploriert und somit den suboptimalen Zielpfad nie gefunden.

% TODO Heuristische Suche ergänzen

\pagebreak

\section{Prüfungsfragen}
\begin{enumerate}
    \item Was ist KI?
    \item Was ist Suche?
    \begin{enumerate}
        \item Suchproblem modellieren
        \item KEIN Min-Max wird abgefragt!
        \item Beispiel $\rightarrow$ Navigationssystem (Lösung: nicht der kürzeste Weg, sondern ein Pfad.)
        \begin{itemize}
            \item Knoten: Orte in Stadt
            \item Kanten: Aktionen von Ort zu Ort
            \item $\rightarrow$ generiert von Startknoten aus.
            \item Suchverfahren: Breitensuche, Tiefensuche, Heuristik
            \item Breitensuche:
            \begin{enumerate}
                \item Kosten: Zeit / Entfernung $\infty > Kosten > 0$
                \item Handlungsmöglichkeiten $< \infty$
            \end{enumerate}
            Heuristik:
            \begin{itemize}
                \item effizienter: $\rightarrow$ Zeit und Speicheraufwand
                \item Bspw.: Luftlinie als Heuristik
                \item Eine Heuristik ist zulässig, wenn
                \begin{itemize}
                    \item[$\rightarrow$] optimale Lösung $\rightarrow$ 
                    \item[$\rightarrow$] monotoniebeschränkung $\rightarrow$ Warum führt die monotoniebeschränkung dazu, dass man nicht zweimal den gleichen Weg findet? 
                \end{itemize}
            \end{itemize}
            \item A-Algorithmus
            \begin{itemize}
                \item[$\rightarrow$] open-list zu exp. Knoten $f(n) = h(n) + g(n)$ 
                \item[$\rightarrow$] closed-list (braucht man eigentlich nicht, da die Heuristik monotoniebeschränkt ist)
            \end{itemize}
        \end{itemize}
    \end{enumerate}
    \item Logik
    \begin{itemize}
        \item Resolution ($\rightarrow$ siehe oben)
        \item Logische Konsequenz
        \item Kalkül
        \begin{itemize}
            \item Sprache (Symbole und syntaktische Regeln) $\Gamma_\alpha= \{P \; |\; \delta_\alpha \vdash_\alpha P\}$
            \item Ableitungsregeln
            \item Axiome
        \end{itemize}
        \item Wissen
        \begin{itemize}
            \item Trinität: Glaube, Rechtfertigung, Wahrheit (Wahrheitswerttabelle aufstellen und ausführlich erklären)
            \item Gettier-Beispiele, Buridan-Sätze (kann man nicht mit dieser Trinität aufstellen, weil es einen Selbstbezug gibt)
        \end{itemize}
    \end{itemize}
    \item Mögliche Welten und Agenten
    \begin{itemize}
        \item semantic attachment: Wenn wir neue Aussage aus unserer Welt bkeommen, die noch nicht in unseren Beliefs sind, dannn können wir die nutzen um neue Aussagen in usner Beliefsystem aufzunehmen.
        \begin{align*}
            B_\alpha(\Phi_1) \lor \Psi_1 \\
            \vdots \\
            B_\alpha(\Phi_n) \lor \Psi_n \\
            \lnot B_\alpha(\Psi_{n+1}) \lor \Psi_{n+1} \\
            \phi_1 \land \phi_2 \land \dots \land \psi_n \vdash \phi_{n+1} \\
            \hline
            \psi_1 \lor \psi_2 \lor \dots \lor \psi_{n+1}
        \end{align*}
        \begin{align*}
            B_\alpha(\phi_1) \lor \text{ kein Vogel} \\
            \lnot B_\alpha(\phi_2) \lor \text{ kein Säugetier} \\
            \text{kann fliegen } \vdash \text{ hat Flügel}
        \end{align*}
    \end{itemize}
    \item Nicht-Monotonie (wird er nicht so tief fragen, er geht eher auf Objektzentrierte Wissensrepräsentation ein)
    \begin{itemize}
        \item Wenn wir einmal etwas festlgelegt haben, können wir keine Widersprüche glauben. 
        \item $\rightarrow$ Poole-Erweiterung (sind Defaults) $\hookrightarrow$ Wir behalten die Maximale Menge an Normalitäten und ersetzen nur mit einer minimalen Menge an Abnormalitäten. Wir versuchen möglichst viel von unserem Wissen zu behalten und möglichst wenig wegzuwerfen.
    \end{itemize}
    \item Objektzentrierte Wissensrepräsentation
    \item Ontologie (legt er fokus), A-Box, T-Box erklären können, Warum ist die T-Box gerade die Ontologie?
    \item Die Objekte sind Anreicherung des Wissensgraphen mit konkreten Beispielen
    \item Probleme aus der Objektzentrierten Wissensrepräsentation werden durch probabilistisches Schließen gelöst. Also sollte man erklären können, wie die Probleme gelöst werden.
\end{enumerate}

\end{document}
 